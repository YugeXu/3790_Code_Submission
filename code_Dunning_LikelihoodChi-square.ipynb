{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math 3790 W01\n",
    "## Yuge Xu 1194170\n",
    "## NLP Method: Dunning Likelihood Ratio Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import bigrams\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sentences) = 37715\n",
      "len(words) = 755386\n",
      "number of bigrams in corpus: N = 755385\n"
     ]
    }
   ],
   "source": [
    "# read txt files\n",
    "with open(\"Corpus_Country_History.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "text = text.replace('\\n', ' ')\n",
    "# split words\n",
    "words = word_tokenize(text)\n",
    "# filter punctuation marks\n",
    "words = [word for word in words if word.isalpha()]\n",
    "# split senetence\n",
    "sentences = sent_tokenize(text)\n",
    "print(f\"len(sentences) = {len(sentences)}\")\n",
    "print(f\"len(words) = {len(words)}\")\n",
    "bigram_list = list(bigrams(words))\n",
    "N = len(bigram_list)\n",
    "print(f\"number of bigrams in corpus: N = {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Log Ratio Value\n",
    "def get_log_lambada_value_for_collocation(word1,word2):\n",
    "    def count_word_occurrences(input_sentences, input_searched_word):\n",
    "    # Convert the target word to lower case\n",
    "        word_to_count_lower = input_searched_word.lower()\n",
    "        count = 0\n",
    "        for sentence in input_sentences:\n",
    "            words = [word.lower() for word in word_tokenize(sentence) if word.isalpha()]\n",
    "            count += words.count(word_to_count_lower)\n",
    "        return count\n",
    "    def find_target_bigram_num(input_bigram_list, input_target_bigram):\n",
    "        count_bigram = 0\n",
    "        # Converts all the words in the target bigram to lowercase\n",
    "        target_bigram_lower = tuple(word.lower() for word in input_target_bigram)\n",
    "        for bigram in input_bigram_list:\n",
    "            bigram_lower = tuple(word.lower() for word in bigram)\n",
    "            if bigram_lower == target_bigram_lower:\n",
    "                count_bigram += 1\n",
    "        return count_bigram\n",
    "    \n",
    "    num_word1 = count_word_occurrences(sentences, word1)\n",
    "    num_word2 = count_word_occurrences(sentences,word2)\n",
    "    target_bigram = (word1,word2)\n",
    "    num_word1_word2 = find_target_bigram_num(bigram_list,target_bigram)\n",
    "\n",
    "    num_w1_nw2 = num_word1 - num_word1_word2\n",
    "    num_nw1_w2 = num_word2 - num_word1_word2\n",
    "    num_nw1 = N - num_word1\n",
    "    num_nw2 = N - num_word2\n",
    "    num_nw1_nw2 = N - num_word1-num_word2+num_word1_word2\n",
    "\n",
    "    null_hypothesis_p = num_word2/N\n",
    "    alter_hypothesis_p1 = num_word1_word2/num_word1\n",
    "    alter_hypothesis_p2 = (num_nw1_w2)/(num_nw1)\n",
    "\n",
    "\n",
    "# part1 = b(c12;c1,p) ;    part2 = b(c2-c12;N-c1,p) \n",
    "    part1 = binom.pmf(num_word1_word2,num_word1,null_hypothesis_p)\n",
    "    part2 = binom.pmf(num_nw1_w2,num_nw1,null_hypothesis_p)\n",
    "    LH0 = part1*part2\n",
    "\n",
    "\n",
    "# part3 = b(c12;c1,p1) ;    part4 = b(c12;c1,p2)\n",
    "    part3 = binom.pmf(num_word1_word2,num_word1,alter_hypothesis_p1)\n",
    "    part4 = binom.pmf(num_nw1_w2,num_nw1,alter_hypothesis_p2)\n",
    "    LH1 = part3*part4\n",
    "\n",
    "    base = 2 \n",
    "    lambda_value = LH0/LH1\n",
    "    log_lambda = math.log(lambda_value,base)\n",
    "  \n",
    "\n",
    "\n",
    "    print(f\"The word '{word1}' appears {num_word1} times in the text.\")\n",
    "    print(f\"The word '{word2}' appears {num_word2} times in the text.\")\n",
    "    print(f\"The bigram '{target_bigram}' appears {num_word1_word2} times in the bigram list.\")\n",
    "\n",
    "\n",
    "    print(f\"num_word1_not_word2 = {num_w1_nw2}\")\n",
    "    print(f\"num_not_word1_word2 = {num_nw1_w2}\")\n",
    "    print(f\"num_not_word1 = {num_nw1}\")\n",
    "    print(f\"num_not_word2 = {num_nw2}\")\n",
    "    print(f\"num_not_word1_not_word2 = {num_nw1_nw2}\")\n",
    "\n",
    "    print(\"******\")\n",
    "    print(f\"null_hypothesis_p = {null_hypothesis_p}\")\n",
    "    print(f\"alter_hypothesis_p1 = {alter_hypothesis_p1}\")\n",
    "    print(f\"alter_hypothesis_p2 = {alter_hypothesis_p2}\")\n",
    "\n",
    "\n",
    "    print(\"******\")\n",
    "    print(f\"L(H0) = {LH0}\")\n",
    "    print(f\"L(H1) = {LH1}\")\n",
    "    print(f\"log_lambda = {log_lambda}\")\n",
    "    print(f\"-2log_lambda = {(-2)*(log_lambda)}\")    \n",
    "    return log_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'world' appears 915 times in the text.\n",
      "The word 'people' appears 1641 times in the text.\n",
      "The bigram '('world', 'people')' appears 1 times in the bigram list.\n",
      "num_word1_not_word2 = 914\n",
      "num_not_word1_word2 = 1640\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 753744\n",
      "num_not_word1_not_word2 = 752830\n",
      "******\n",
      "null_hypothesis_p = 0.002172402152544729\n",
      "alter_hypothesis_p1 = 0.001092896174863388\n",
      "alter_hypothesis_p2 = 0.0021737113470383183\n",
      "******\n",
      "L(H0) = 0.0026847748889006215\n",
      "L(H1) = 0.0036297902274673743\n",
      "log_lambda = -0.4350850473073696\n",
      "-2log_lambda = 0.8701700946147392\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The word 'world' appears 915 times in the text.\n",
      "The word 'movement' appears 296 times in the text.\n",
      "The bigram '('world', 'movement')' appears 1 times in the bigram list.\n",
      "num_word1_not_word2 = 914\n",
      "num_not_word1_word2 = 295\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 755089\n",
      "num_not_word1_not_word2 = 754175\n",
      "******\n",
      "null_hypothesis_p = 0.00039185316097089563\n",
      "alter_hypothesis_p1 = 0.001092896174863388\n",
      "alter_hypothesis_p2 = 0.0003910029557172585\n",
      "******\n",
      "L(H0) = 0.005816054844891421\n",
      "L(H1) = 0.008548781590612885\n",
      "log_lambda = -0.5556779416923434\n",
      "-2log_lambda = 1.1113558833846868\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The word 'world' appears 915 times in the text.\n",
      "The word 'home' appears 290 times in the text.\n",
      "The bigram '('world', 'home')' appears 1 times in the bigram list.\n",
      "num_word1_not_word2 = 914\n",
      "num_not_word1_word2 = 289\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 755095\n",
      "num_not_word1_not_word2 = 754181\n",
      "******\n",
      "null_hypothesis_p = 0.0003839101914917559\n",
      "alter_hypothesis_p1 = 0.001092896174863388\n",
      "alter_hypothesis_p2 = 0.00038305035322809387\n",
      "******\n",
      "L(H0) = 0.00579873733024215\n",
      "L(H1) = 0.008636982380503306\n",
      "log_lambda = -0.5747885576087175\n",
      "-2log_lambda = 1.149577115217435\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The word 'world' appears 915 times in the text.\n",
      "The word 'supply' appears 117 times in the text.\n",
      "The bigram '('world', 'supply')' appears 1 times in the bigram list.\n",
      "num_word1_not_word2 = 914\n",
      "num_not_word1_word2 = 116\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 755268\n",
      "num_not_word1_not_word2 = 754354\n",
      "******\n",
      "null_hypothesis_p = 0.00015488790484322564\n",
      "alter_hypothesis_p1 = 0.001092896174863388\n",
      "alter_hypothesis_p2 = 0.00015375031479051518\n",
      "******\n",
      "L(H0) = 0.004539226911839562\n",
      "L(H1) = 0.013625278620029218\n",
      "log_lambda = -1.5857672173046766\n",
      "-2log_lambda = 3.1715344346093532\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The word 'world' appears 915 times in the text.\n",
      "The word 'history' appears 923 times in the text.\n",
      "The bigram '('world', 'history')' appears 5 times in the bigram list.\n",
      "num_word1_not_word2 = 910\n",
      "num_not_word1_word2 = 918\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 754462\n",
      "num_not_word1_not_word2 = 753552\n",
      "******\n",
      "null_hypothesis_p = 0.0012218934715410024\n",
      "alter_hypothesis_p1 = 0.00546448087431694\n",
      "alter_hypothesis_p2 = 0.0012167481808421806\n",
      "******\n",
      "L(H0) = 6.184351340832448e-05\n",
      "L(H1) = 0.0023179265779045546\n",
      "log_lambda = -5.228068775451574\n",
      "-2log_lambda = 10.456137550903147\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The word 'world' appears 915 times in the text.\n",
      "The word 'bank' appears 144 times in the text.\n",
      "The bigram '('world', 'bank')' appears 9 times in the bigram list.\n",
      "num_word1_not_word2 = 906\n",
      "num_not_word1_word2 = 135\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 755241\n",
      "num_not_word1_not_word2 = 754335\n",
      "******\n",
      "null_hypothesis_p = 0.00019063126749935464\n",
      "alter_hypothesis_p1 = 0.009836065573770493\n",
      "alter_hypothesis_p2 = 0.00017893355600620304\n",
      "******\n",
      "L(H0) = 8.670203454424835e-15\n",
      "L(H1) = 0.004543904840215688\n",
      "log_lambda = -38.931003912434356\n",
      "-2log_lambda = 77.86200782486871\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The word 'world' appears 915 times in the text.\n",
      "The word 'war' appears 1655 times in the text.\n",
      "The bigram '('world', 'war')' appears 166 times in the bigram list.\n",
      "num_word1_not_word2 = 749\n",
      "num_not_word1_word2 = 1489\n",
      "num_not_word1 = 754470\n",
      "num_not_word2 = 753730\n",
      "num_not_word1_not_word2 = 752981\n",
      "******\n",
      "null_hypothesis_p = 0.002190935747996055\n",
      "alter_hypothesis_p1 = 0.1814207650273224\n",
      "alter_hypothesis_p2 = 0.00197357085106101\n",
      "******\n",
      "L(H0) = 7.793358283937863e-262\n",
      "L(H1) = 0.0003539698443239373\n",
      "log_lambda = -855.9188297964151\n",
      "-2log_lambda = 1711.8376595928303\n"
     ]
    }
   ],
   "source": [
    "word1 = \"world\"\n",
    "word2 = \"people\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "word1 = \"world\"\n",
    "word2 = \"movement\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "word1 = \"world\"\n",
    "word2 = \"home\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "word1 = \"world\"\n",
    "word2 = \"supply\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "word1 = \"world\"\n",
    "word2 = \"history\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "word1 = \"world\"\n",
    "word2 = \"bank\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "word1 = \"world\"\n",
    "word2 = \"war\"\n",
    "value = get_log_lambada_value_for_collocation(word1,word2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
